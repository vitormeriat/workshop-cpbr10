{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CrazyTechGuys](http://www.crazytechguys.com/wp-content/uploads/2016/02/logoCTG-4.png)\n",
    "\n",
    "\n",
    "\n",
    "# Workshop Machine Learning\n",
    "\n",
    "\n",
    "## Importando os módulos necessários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt      \n",
    "\n",
    "# Usamos isso para determiniar que os gráficos resultantes devem ser renderizados no jupyter.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neste ponto carregamos os dados do arquivo específico em um objeto chamado df\n",
    "# Nosso dataset agora será um dataframe\n",
    "df = pd.read_csv(\"./pima-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando o formato do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Com essa função sabemos quantas linhas e colunas tem nosso\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando os tipos de dados do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aqui conseguimos determinar com quais tipos de dados estamos trabalhando em cada coluna ou atributo\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando as 10 primeiras linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Função que exibe a quantidade de linhas estipuladas do início do dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verficando as 10 últimas linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Função que exibe a quantidade de linhas estipuladas do final do dataset\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprofundando na análise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Se não estipularmos nenhum parâmetro, por default na função head() teremos as 5 primeiras linhas de um dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função **describe()** é extremamente importane para uma análise rápida e para se ter uma ídeia dos dados que estão sendo manipulados. Esta função realiza calculos estatísticos para cada coluna numérica do DataFrame, como contagem de valores, soma, média, mediana, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procurando valores Null ou Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verificando se existe algum valor nulo no dataset\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ainda podemos verificar essa informação olhanda a soma de valores nulos por linha e atributos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso em específico, temos um problema. Não encontramos nenhum valor null, porém seria um erro descartar que possa existir valores errados no dataset.\n",
    "\n",
    "> Este é um ponto importante. A maneira como encontramos, determinados e tratamos os valores nulos é fundamental para o resultado.\n",
    "\n",
    "Vale lembrar que grande parte do trabalho é gasto no **tratamento de dados**. Neste caso é bom salientar que é muito comum em diversos datasets os valores null, serem substituídos por 0, logo, é sempre bom olhar para estas ocorrências com cuidado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"glucose_conc: \" + str(len(df.loc[df.glucose_conc == 0])))\n",
    "print(\"diastolic_bp: \" + str(len(df.loc[df['diastolic_bp'] == 0])))\n",
    "print(\"thickness: \" + str(len(df.loc[df['thickness'] == 0])))\n",
    "print(\"insulin: \" + str(len(df.loc[df['insulin'] == 0])))\n",
    "print(\"bmi: \" + str(len(df.loc[df['bmi'] == 0])))\n",
    "print(\"age: \" + str(len(df.loc[df['age'] == 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro tratamento nos dados\n",
    "\n",
    "### Facilitando a classificação da coluna diabetes\n",
    "\n",
    "Vamos iniciar nosso tratamento de dados fazendo uma simples substituição. A fim de facilitar nosso trabalho na aprendizagem, vamos substituir os valores boleanos da coluna diabetes por 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verificando as primeiras linhas do dataset\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definindo as classes\n",
    "diabetes_map = {True : 1, False : 0}\n",
    "\n",
    "# Aplicando o mapeamento ao dataset\n",
    "df['diabetes'] = df['diabetes'].map(diabetes_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verificando as primeiras linhas do dataset\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando como os dados estão distribuídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_true = len(df.loc[df.diabetes] == True)\n",
    "num_false = len(df.loc[df.diabetes] == False)\n",
    "\n",
    "print(\"Casos Verdadeiros: {0} ({1:2.2f}%)\".format(num_true, (num_true/ (num_true + num_false)) * 100))\n",
    "print(\"Casos Falsos     : {0} ({1:2.2f}%)\".format(num_false, (num_false/ (num_true + num_false)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo os dados\n",
    "\n",
    "Agora chegamos ao ponto em que precisamos dividir os nossos dados entre os subsets de treino e avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seleção de variáveis (Feature Selection)\n",
    "atributos = ['num_preg', 'glucose_conc', 'diastolic_bp', 'thickness', 'insulin', 'bmi', 'diab_pred', 'age']\n",
    "\n",
    "# Variável a ser prevista\n",
    "atrib_prev = ['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando objetos\n",
    "X = df[atributos].values\n",
    "Y = df[atrib_prev].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definindo a taxa de split\n",
    "split_test_size = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando dados de treino e de teste\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size = split_test_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imprimindo os resultados\n",
    "print(\"{0:0.2f}% nos dados de treino\".format((len(X_treino)/len(df.index)) * 100))\n",
    "print(\"{0:0.2f}% nos dados de teste\".format((len(X_teste)/len(df.index)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando os subsets de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Original True : {0} ({1:0.2f}%)\".format(\n",
    "        len(df.loc[df.diabetes == 1]), (\n",
    "        len(df.loc[df.diabetes ==1])/len(df.index) * 100)))\n",
    "\n",
    "print(\"Original False : {0} ({1:0.2f}%)\".format(\n",
    "        len(df.loc[df.diabetes == 0]), (\n",
    "        len(df.loc[df.diabetes == 0])/len(df.index) * 100)))\n",
    "\n",
    "print(\"\\nTraining True : {0} ({1:0.2f}%)\".format(\n",
    "        len(Y_treino[Y_treino[:] == 1]), (\n",
    "        len(Y_treino[Y_treino[:] == 1]) / len(Y_treino) * 100)))\n",
    "\n",
    "print(\"Training False : {0} ({1:0.2f}%)\".format(\n",
    "        len(Y_treino[Y_treino[:] == 0]), (\n",
    "        len(Y_treino[Y_treino[:] == 0])/len(Y_treino) * 100)))\n",
    "\n",
    "print(\"\\nTest True : {0} ({1:0.2f}%)\".format(\n",
    "        len(Y_teste[Y_teste[:] == 1]), (\n",
    "        len(Y_teste[Y_teste[:] == 1])/len(Y_teste) * 100)))\n",
    "\n",
    "print(\"Test False : {0} ({1:0.2f}%)\".format(\n",
    "        len(Y_teste[Y_teste[:] == 0]), (\n",
    "        len(Y_teste[Y_teste[:] == 0])/len(Y_teste) * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo tratamento nos dados\n",
    "\n",
    "### Tralhando os valores com zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando objeto\n",
    "preenche_0 = Imputer(missing_values = 0, strategy = \"mean\", axis = 0)\n",
    "\n",
    "# Substituindo os valores iguais a zero, pela média dos dados\n",
    "X_treino = preenche_0.fit_transform(X_treino)\n",
    "X_teste = preenche_0.fit_transform(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Agora é a hora da mágica ;)\n",
    "\n",
    "## Vamos criar nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilizando um classificador Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando o modelo preditivo\n",
    "modelo_v1 = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... agora vamos treinar ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "modelo_v1.fit(X_treino, Y_treino.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e verificar a Acurácia / Precisão dos dados de  TREINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_predict_train = modelo_v1.predict(X_treino)\n",
    "print(\"Precisão: {0:.4f}\\n\".format(metrics.accuracy_score(Y_treino, nb_predict_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nosso próximo passo é verificar os dados de TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_predict_test = modelo_v1.predict(X_teste)\n",
    "print(\"Precisão: {0:.4f}\\n\".format(metrics.accuracy_score(Y_teste, nb_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Obrigado a todos...\n",
    "\n",
    "**:)** \n",
    "\n",
    "[Vitor Meriat](http://www.vitormeriat.com.br/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
